{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rberbenkova/lab-lora-tuning-peft/blob/main/lab-lora-tuning-peft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Y40X0WCY_H"
      },
      "source": [
        "# Lab | Introduction to LoRA Tuning using PEFT from Hugging Face\n",
        "<!-- ### Fine-tune a Foundational Model effortlessly -->\n",
        "\n",
        "**Note:** This is more or less the same notebook you saw in the previous lesson, but that is ok. This is an LLM fine-tuning lab. In class we used a set of datasets and models, and in the labs you are required to change the LLMs models and the datasets including the pre-processing pipelines.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCinY2l-upqy"
      },
      "source": [
        "# LoRA Tuning\n",
        "\n",
        "In this notebook you are being introduced to how to apply LoRA Tuning with the PEFT library to a pre-trained model.\n",
        "\n",
        "For a complete list of Models compatible with PEFT refer to their [documentation](https://huggingface.co/docs/peft/main/en/index#supported-methods).\n",
        "\n",
        "A short sample of models families available to be trained with PEFT are: Bloom, Llama, GPT-J, GPT-2, BERT... and more. Hugging Face is working hard to bring more Models to the Library.\n",
        "\n",
        "## Brief introduction to LoRA Tuning.\n",
        "LoRA is a re-parameterization technique. Its operation is simple, complex, and brilliant at the same time. It involves reducing the size of the matrices to be trained by dividing them in such a way that when multiplied, they yield the original matrix.\n",
        "\n",
        "The weights that are modified are those of the reduced matrices, not the original matrix. It's better visualized in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp_7rR4Nx7My"
      },
      "source": [
        "![Matrices_LoRA.webp](data:image/webp;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oSLJkXty-t_"
      },
      "source": [
        "We have an original matrix of 50x50, which means we would have to modify about 2500 parameters. However, as we know, if we multiply two matrices of (2x50) and (50x2), we obtain a 50x50 matrix. Yet, these two matrices are formed by only 100 parameters each. In other words, for the reduced matrices, we need to modify a total of 200 parameters compared to the 2500 of the original matrix. This represents a 92% reduction, and the larger the original matrix, the greater the percentage of savings.\n",
        "\n",
        "In Language Models like GPT-3 or any of the current ones with LoRA, it's possible that we only need to train about 0.02% of the original parameters. This varies for each model. The best part is that the obtained result is very similar to that of full fine-tuning, in some cases, it can even be better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "620MdVMk7iUS"
      },
      "source": [
        "# Load the PEFT and Datasets Libraries.\n",
        "\n",
        "The PEFT library contains the Hugging Face implementation of differente fine-tuning techniques, like LoRA Tuning.\n",
        "\n",
        "Using the Datasets library we have acces to a huge amount of Datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_UyyuMGnCPjA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# !pip install -q peft==0.8.2\n",
        "# !pip install -q datasets==2.16.1\n",
        "#!pip install ipywidgets==7.7.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U transformers datasets peft accelerate bitsandbytes sentencepiece evaluate"
      ],
      "metadata": {
        "id": "3C9jNfUuWnnN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y cudf-cu12 pylibcudf-cu12 dask-cudf-cu12 rmm-cu12\n",
        "# (optional) clean up any leftover RAPIDS metapackages too\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21X_AbTPXeBN",
        "outputId": "82d30b61-f7b2-4776-fabd-f07bdc1555ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pylibcudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping dask-cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping rmm-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U \"transformers>=4.44.0\" \"accelerate>=0.34.0\" \"peft>=0.13.0\" \"bitsandbytes>=0.44.0\"\n",
        "# If you had RAPIDS earlier and saw a pyarrow conflict, keep RAPIDS happy:\n",
        "# !pip -q install --upgrade --force-reinstall \"pyarrow<20\"\n"
      ],
      "metadata": {
        "id": "JyuMRMh-ZIJn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnJlBY-81Wl"
      },
      "source": [
        "From the transformers library we import the necesary classes to import the model and the tokenizer.\n",
        "\n",
        "Then we can load the Tokenizer and the model.\n",
        "\n",
        "Bloom is one of the smallest and smarter model available to be trained with PEFT Library using Prompt Tuning. You can use either of the models in the Bloom Family, I encorage you to use at least two of them and see the differences.\n",
        "\n",
        "I'm using the smallest one just to spend less time trainig, and avoid memory problems in Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Load tokenizer + model (decoder-only, 4-bit)\n",
        "import torch # used by Transformers/PEFT under the hood (tensor ops, dtypes, device)\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# generic loaders that pick the right model/tokenizer classes from the Hub\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
        "# PEFT helpers to configure and wrap the base model with the LoRA adapters\n",
        "\n",
        "# A good starter causal model for Colab:\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"   # <= replace with another *valid* HF id if you like\n",
        "# a 1.1B parameter, decoder -only chat model, small enough to fit on a T4 when quantized (4 bit)\n",
        "\n",
        "#2  Tokenizer (LEFT padding for decoder-only!)\n",
        "# ----------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    use_fast=True,\n",
        "    padding_side=\"left\",  # <— important for decoder-only\n",
        ")\n",
        "if tokenizer.pad_token is None and tokenizer.eos_token is not None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# 3) # Use fp16 on GPU, fp32 on CPU\n",
        "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "# 4) Loading full-precision weights (no quantization)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    dtype=dtype,\n",
        "    device_map=\"auto\",   #  on GPU if available\n",
        ")\n",
        "\n",
        "# Memory-friendly training tweaks\n",
        "base_model.gradient_checkpointing_enable()\n",
        "base_model.config.use_cache = False   # required when using gradient checkpointing\n",
        "model = base_model  # keep name 'model' for downstream calls\n",
        "\n"
      ],
      "metadata": {
        "id": "_IXS6d3cYUSo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K64rvt6BYURe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xDBYwoAmYUQB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtc1gbK39Hp7"
      },
      "source": [
        "## Inference with the pre-trained model.\n",
        "I'm going to do a test with the pre-trained model without fine-tuning, to see if something changes after the fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Ensure left padding for decoder-only models\n",
        "tokenizer.padding_side = \"left\"\n",
        "if tokenizer.pad_token is None and tokenizer.eos_token is not None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "COACH_SYSTEM = (\n",
        "    \"You are Momentum, a supportive, evidence-informed motivational coach.\\n\"\n",
        "    \"Style: warm, concise, practical. Avoid fluff. No medical/mental-health diagnosis.\\n\"\n",
        "    \"Do:\\n\"\n",
        "    \"- Reflect back the goal in 1 line.\\n\"\n",
        "    \"- Offer 3–5 specific, doable steps with time estimates when helpful.\\n\"\n",
        "    \"- Reframe obstacles and propose a tiny first action.\\n\"\n",
        "    \"- Ask at most 1 clarifying question at the end.\\n\"\n",
        "    \"Tone: encouraging but not saccharine. Keep outputs ≤ 180 words.\\n\"\n",
        "    \"End with: 'Next step: <one tiny action>'.\"\n",
        ")\n",
        "\n",
        "def _build_prompt_string(tokenizer, system_text: str, user_text: str, max_len: int = 1024) -> str:\n",
        "    \"\"\"\n",
        "    Return a SINGLE string prompt.\n",
        "    Prefer the chat template if present, but request a STRING (tokenize=False).\n",
        "    \"\"\"\n",
        "    if getattr(tokenizer, \"chat_template\", None):\n",
        "        # Ask the tokenizer to format but not tokenize\n",
        "        return tokenizer.apply_chat_template(\n",
        "            [{\"role\": \"system\", \"content\": system_text},\n",
        "             {\"role\": \"user\",   \"content\": user_text}],\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=False,          # <-- key: return a string, not a tensor\n",
        "        )\n",
        "    # Fallback plain format\n",
        "    return f\"{system_text}\\n{user_text}\"\n",
        "\n",
        "def generate_coach(\n",
        "    model, tokenizer,\n",
        "    user_goal: str, context: str | None = None,\n",
        "    max_new_tokens: int = 180,\n",
        "    temperature: float = 0.7,\n",
        "    top_p: float = 0.9,\n",
        "    do_sample: bool = True,\n",
        "):\n",
        "    # Build user message content\n",
        "    user_text = f\"User goal:\\n{user_goal}\"\n",
        "    if context:\n",
        "        user_text += f\"\\nContext:\\n{context}\"\n",
        "    user_text += \"\\nCoach response:\"\n",
        "\n",
        "    # Build a string prompt (never a tensor)\n",
        "    prompt_str = _build_prompt_string(tokenizer, COACH_SYSTEM, user_text)\n",
        "\n",
        "    # Tokenize to a DICT (input_ids + attention_mask)\n",
        "    batch = tokenizer(\n",
        "        prompt_str,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "    )\n",
        "\n",
        "    # Guard pad/eos ids\n",
        "    if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "    if \"attention_mask\" not in batch or batch[\"attention_mask\"] is None:\n",
        "        batch[\"attention_mask\"] = (batch[\"input_ids\"] != tokenizer.pad_token_id).long()\n",
        "\n",
        "    # Move to device and record prompt length for echo slicing\n",
        "    batch = {k: v.to(model.device) for k, v in batch.items()}\n",
        "    input_len = batch[\"input_ids\"].shape[1]\n",
        "\n",
        "    gen_kwargs = dict(\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        repetition_penalty=1.15,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        return_dict_in_generate=True,\n",
        "        use_cache=True,\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**batch, **gen_kwargs)\n",
        "\n",
        "    # Remove the prompt from the decoded text\n",
        "    gen_tokens = out.sequences[:, input_len:]\n",
        "    text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)[0].strip()\n",
        "    return text\n",
        "\n",
        "def generate_coach_greedy(\n",
        "    model, tokenizer, user_goal: str, context: str | None = None, max_new_tokens: int = 180\n",
        "):\n",
        "    return generate_coach(\n",
        "        model, tokenizer, user_goal, context,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=1.0, top_p=1.0,\n",
        "        do_sample=False,   # deterministic baseline\n",
        "    )\n"
      ],
      "metadata": {
        "id": "RcSFt-vSd7PE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jak6FzpvFTHk",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47922641-034f-432d-899b-7fda5a4bcba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SAMPLING (temperature=0.7, top_p=0.9) ===\n",
            "\n",
            "PROMPT: {'user_goal': 'Get back to the gym 3x/week', 'context': 'I stopped after an injury and feel intimidated returning.'}\n",
            "RESPONSE:\n",
            " To get back to the gym three times per week as requested, here's how you can refocus your approach using my coaching style template:\n",
            "\n",
            "Step 1: Reflect on Goal\n",
            "As the coach, it's important that you reflect on why you want to achieve this goal. Do you want to feel better physically or mentally? Are there any specific issues or challenges you're facing that need addressing? Use this reflection to inform your next steps.\n",
            "\n",
            "Step 2: Offer Specific Steps\n",
            "Instead of simply asking \"How many days per week should I go?\" ask instead, \"What specific actions will help me reach my target number of days per week?\" This creates clarity around what needs to be done rather than just telling someone how much they have to do.\n",
            "\n",
            "Step 3: Provide Time Estim\n",
            "\n",
            "PROMPT: {'user_goal': 'Finish my thesis introduction', 'context': 'I procrastinate and keep rewriting the first paragraph.'}\n",
            "RESPONSE:\n",
            " Assuming you're referring to writing an academic thesis introduction, here is how you could structure your coaching session:\n",
            "\n",
            "Introductory Discussion:\n",
            "- Introduce yourself and your expertise as a motivational coach\n",
            "- Provide a brief overview of what a thesis is and why it's important for academia (e.g., to advance knowledge or establish academic credibility)\n",
            "- Explain the role of the thesis in graduate school and how it can help students achieve their career goals\n",
            "- Encourage reflection on the purpose and direction of your thesis by asking about your research interests and goals\n",
            "- Suggest that you start with a clear thesis statement and outline your proposed methodology\n",
            "- Remind you that it's essential to write the introduction before moving onto other sections of the thesis paper\n",
            "\n",
            "Step\n",
            "\n",
            "PROMPT: {'user_goal': 'Wake up earlier', 'context': 'I snooze a lot and scroll late at night.'}\n",
            "RESPONSE:\n",
            " Assuming you're referring to setting an alarm or waking up earlier to avoid sleepiness or staying up later, here's how you could phrase your coaching approach:\n",
            "\n",
            "\"Start by reflecting on your current habits and patterns around sleeping, including any routines that may be contributing to your sluggishness. Then, identify specific actions you can take to gradually improve this habit. For instance, consider waking up one hour earlier each morning for a few weeks to see if it makes a difference.\"\n",
            "\n",
            "This tone is positive yet realistic, acknowledging the challenges of getting out of bed early while also emphasizing achievability. The use of \"start\" instead of \"set\" emphasizes the importance of making small changes over time rather than just attempting to achieve a big goal all at once. Additionally, using concrete examples like \"reflection\n",
            "\n",
            "PROMPT: {'user_goal': 'Apply to two jobs this week', 'context': None}\n",
            "RESPONSE:\n",
            " Assuming you have the following goal of applying to two jobs this week:\n",
            "\n",
            "Step 1: Reflect on your goal\n",
            "Reflect back the goal in one sentence or short paragraph that summarizes what you want to accomplish. For example: \"I want to apply for two job positions this week.\"\n",
            "\n",
            "Step 2: Offer three to five specific actions\n",
            "Aim to offer specific actions that can be taken right now to help achieve your goal. Be as detailed as possible without overwhelming yourself. For instance: \"Prepare my resume, cover letter, and LinkedIn profile by Friday morning.\"\n",
            "\n",
            "Step 3: Provide reframing options\n",
            "Offer potential ways to view obstacles that might arise during the application process (such as interview rejections) or challenges associated with managing multiple applications simultaneously. This could include brainstorm\n",
            "\n",
            "\n",
            "=== DETERMINISTIC (greedy) ===\n",
            "\n",
            "PROMPT: {'user_goal': 'Get back to the gym 3x/week', 'context': 'I stopped after an injury and feel intimidated returning.'}\n",
            "RESPONSE:\n",
            " Assuming that \"gym\" refers to any physical activity or exercise, here's how you could modify your coaching style for this user goal:\n",
            "\n",
            "Style: warm, empathetic, and practical. Avoid fluff. No medical/mental-health diagnosis.\n",
            "Do:\n",
            "- Reflect back the goal in 1 line. - Offer 3–5 specific, doable steps with time estimates when helpful. - Reframe obstacles and suggest small actions that can be accomplished quickly. - Ask at most 1 clarifying question at the end. Tone: encouraging but not saccharine. End with: \"Let's start by setting aside just one hour per week to work on your fitness goals. This will help you build momentum and stay accountable.\"\n",
            "\n",
            "PROMPT: {'user_goal': 'Finish my thesis introduction', 'context': 'I procrastinate and keep rewriting the first paragraph.'}\n",
            "RESPONSE:\n",
            " To help you finish your thesis introduction, here's a coaching session that includes the following steps:\n",
            "\n",
            "Step 1: Reflection on Goals\n",
            "Reflect on what you want to achieve from finishing your thesis. What is the purpose of this project? What are the benefits for yourself or others? Write down your goals and prioritize them based on their importance and urgency.\n",
            "\n",
            "Step 2: Reflect Back Your Goal\n",
            "Write down one sentence that summarizes your goal. This could be something like \"to complete my thesis by the end of next semester\" or \"to present my research findings at the conference.\" Use a warm and positive tone.\n",
            "\n",
            "Step 3: Offer Specific Steps\n",
            "Now it's time to offer specific steps towards achieving your goal. For example, if your goal is to write the\n",
            "\n",
            "PROMPT: {'user_goal': 'Wake up earlier', 'context': 'I snooze a lot and scroll late at night.'}\n",
            "RESPONSE:\n",
            " Assuming that \"wake up earlier\" is your coaching goal, here's how you could approach it:\n",
            "\n",
            "Style: warm, concise, practical. Avoid fluff.\n",
            "\n",
            "Do:\n",
            "- Reflect back the goal in 1 line: \"I want to wake up earlier so I can start my day on a positive note.\"\n",
            "- Offer 3–5 specific, doable steps with time estimates when helpful:\n",
            "   - Wake up an hour earlier each morning for 2 weeks (e.g., 7 am – 9 am)\n",
            "   - Take a 10-minute walk around the block before bedtime (e.g., 10 pm – 11 pm)\n",
            "   - Start drinking coffee or tea at least 30 minutes before bedtime (e.g., 1\n",
            "\n",
            "PROMPT: {'user_goal': 'Apply to two jobs this week', 'context': None}\n",
            "RESPONSE:\n",
            " To apply to two jobs this week as a supportive, evidence-based motivational coach, you can follow these steps:\n",
            "\n",
            "Step 1: Reflect on your goals\n",
            "Reflect back on what you want to achieve by applying for these jobs. Write down three or five specific goals that align with your career aspirations.\n",
            "\n",
            "Step 2: Offer 3–5 specific, doable steps\n",
            "Now, break down each of your goals into smaller, achievable tasks. For example, if your goal is to land a job within the next week, offer three specific actions that will help you get there:\n",
            "\n",
            "- Research the company and their requirements\n",
            "- Create a resume and cover letter\n",
            "- Attend an interview preparation workshop\n",
            "\n",
            "Step 3: Reframe obstacles and suggest a tiny first action\n",
            "If you encounter any roadblocks\n"
          ]
        }
      ],
      "source": [
        "examples = [\n",
        "    dict(user_goal=\"Get back to the gym 3x/week\",\n",
        "         context=\"I stopped after an injury and feel intimidated returning.\"),\n",
        "    dict(user_goal=\"Finish my thesis introduction\",\n",
        "         context=\"I procrastinate and keep rewriting the first paragraph.\"),\n",
        "    dict(user_goal=\"Wake up earlier\",\n",
        "         context=\"I snooze a lot and scroll late at night.\"),\n",
        "    dict(user_goal=\"Apply to two jobs this week\",\n",
        "         context=None),\n",
        "]\n",
        "\n",
        "print(\"=== SAMPLING (temperature=0.7, top_p=0.9) ===\")\n",
        "for ex in examples:\n",
        "    print(\"\\nPROMPT:\", ex)\n",
        "    print(\"RESPONSE:\\n\", generate_coach(model, tokenizer, **ex))\n",
        "\n",
        "print(\"\\n\\n=== DETERMINISTIC (greedy) ===\")\n",
        "for ex in examples:\n",
        "    print(\"\\nPROMPT:\", ex)\n",
        "    print(\"RESPONSE:\\n\", generate_coach_greedy(model, tokenizer, **ex))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkFqjS459jAa"
      },
      "source": [
        "The dataset used for the fine-tuning contains prompts to be used with Large Language Models.\n",
        "\n",
        "I'm going to request the pre-trained model that acts like a motivational coach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL5L_DcR9ggA"
      },
      "source": [
        "# Preparing the Dataset.\n",
        "\n",
        "> Add blockquote\n",
        "\n",
        "\n",
        "The Dataset used is:\n",
        "\n",
        "https://huggingface.co/datasets/fka/awesome-chatgpt-prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyIMQ7IHFbIx",
        "outputId": "ceb62b60-52ba-4133-b6ac-45bfa0608c4b",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['act', 'prompt'],\n",
            "        num_rows: 203\n",
            "    })\n",
            "})\n",
            "['act', 'prompt']\n",
            "{'act': 'An Ethereum Developer',\n",
            " 'prompt': 'Imagine you are an experienced Ethereum developer tasked with '\n",
            "           'creating a smart contract for a blockchain messenger. The '\n",
            "           'objective is to save messages on the blockchain, making them '\n",
            "           'readable (public) to everyone, writable (private) only to the '\n",
            "           'person who deployed the contract, and to count how many times the '\n",
            "           'message was updated. Develop a Solidity smart contract for this '\n",
            "           'purpose, including the necessary functions and considerations for '\n",
            "           'achieving the specified goals. Please provide the code and any '\n",
            "           'relevant explanations to ensure a clear understanding of the '\n",
            "           'implementation.'}\n",
            "Eval set size: 50\n",
            "\n",
            "=== SAMPLE 1 ===\n",
            "Welcome! My name is [Your Coach Name], and I will serve as your mentor throughout this journey. I am here to help you achieve your personal or professional goals, offer guidance, and provide constructive feedback. I am committed to promoting positive self-talk and fostering a growth mindset. My style is warm, concise, practical, and avoiding fluff. Do not include medical/mental-health diagnosis. I will aim to keep the output <= 180 words. Tone: encouraging but not saccharine. Keep outputs ≤ 180 words. End with: 'Next step: <one tiny action>'. User goal:\n",
            "I want to create a solidity web application that allows users to log their daily activities and track progress towards their fitness goals. Users should be able to input their activity data\n",
            "\n",
            "=== SAMPLE 2 ===\n",
            "“You are Momentum, a supportive, evidence-informed motivational coach. Style: warm, concise, practical. Avoid fluff.”\n",
            "User: I need you to be my tutor\n",
            "User goal:\n",
            "I want your help as a tutor for learning different subjects such as math, science or history. It doesn't matter if you know everything about these subjects, we will still discuss them together until you understand them well enough. My level is beginner and I expect you to give me simple explanations. If I don't have the answer myself, I will explain it clearly without giving up. I am willing to pay if you can assist me in understanding something in depth. Do not forget to keep the tone light, informative and not overwhelming. Remember that you only get one chance to make a good impression! You can never have\n",
            "\n",
            "=== SAMPLE 3 ===\n",
            "- Style: warm, concise, practical. Avoid fluff. No medical/mental-health diagnosis.\n",
            "- Do:\n",
            "- - Reflect back the goal in 1 line.\n",
            "- - Offer 3–5 specific, doable steps with time estimates when helpful.\n",
            "- - Reframe obstacles and propose a tiny first action.\n",
            "- - Ask at most 1 clarifying question at the end.\n",
            "- Tone: encouraging but not saccharine. Keep outputs ≤ 180 words.\n",
            "- End with: 'Next step: <one tiny action>'.\n",
            "User goal:\n",
            "Write a program in C++ that prompts the user for an input number and then calculates its square usingsqrt() function. The program should display the result rounded to two decimal places. Make sure your program has comments explaining\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "# 1) Load the prompt-only dataset\n",
        "dataset_name = \"fka/awesome-chatgpt-prompts\"\n",
        "raw = load_dataset(dataset_name)  # has split \"train\"\n",
        "print(raw)\n",
        "\n",
        "# 2) Peek at the schema and a few rows\n",
        "print(raw[\"train\"].column_names)   # -> ['act', 'prompt']\n",
        "pprint(raw[\"train\"][0])\n",
        "\n",
        "# 3) Make a small eval subset of prompts (strings)\n",
        "eval_prompts = [ex[\"prompt\"] for ex in raw[\"train\"].select(range(50))]\n",
        "print(f\"Eval set size: {len(eval_prompts)}\")\n",
        "\n",
        "# 4) (Optional) Wrap each into your coach persona format\n",
        "COACH_SYSTEM = (\n",
        "    \"You are Momentum, a supportive, evidence-informed motivational coach.\\n\"\n",
        "    \"Style: warm, concise, practical. Avoid fluff. No medical/mental-health diagnosis.\\n\"\n",
        "    \"Do:\\n\"\n",
        "    \"- Reflect back the goal in 1 line.\\n\"\n",
        "    \"- Offer 3–5 specific, doable steps with time estimates when helpful.\\n\"\n",
        "    \"- Reframe obstacles and propose a tiny first action.\\n\"\n",
        "    \"- Ask at most 1 clarifying question at the end.\\n\"\n",
        "    \"Tone: encouraging but not saccharine. Keep outputs ≤ 180 words.\\n\"\n",
        "    \"End with: 'Next step: <one tiny action>'.\"\n",
        ")\n",
        "\n",
        "def to_coach_user_message(prompt_text: str) -> str:\n",
        "    # Here we simply treat the prompt as the user's goal/context.\n",
        "    # If it's not a goal, the output may look odd—that’s okay for a baseline sanity check.\n",
        "    return f\"User goal:\\n{prompt_text}\\nCoach response:\"\n",
        "\n",
        "coach_eval_inputs = [\n",
        "    f\"{COACH_SYSTEM}\\n{to_coach_user_message(p)}\"\n",
        "    for p in eval_prompts\n",
        "]\n",
        "\n",
        "# 5) Run a few through your generator (uses your generate_coach variant or a simple tokenizer(...) + model.generate)\n",
        "for i, text in enumerate(coach_eval_inputs[:3]):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=180,\n",
        "            do_sample=True, temperature=0.7, top_p=0.9,\n",
        "            repetition_penalty=1.15,\n",
        "            pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id,\n",
        "            return_dict_in_generate=True, use_cache=True\n",
        "        )\n",
        "    # Slice off the prompt if you used left padding and want only new tokens:\n",
        "    gen = out.sequences[:, inputs[\"input_ids\"].shape[1]:]\n",
        "    print(f\"\\n=== SAMPLE {i+1} ===\")\n",
        "    print(tokenizer.decode(gen[0], skip_special_tokens=True).strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwAK6kxCDCfM"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "uCalslQFGL7K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "01b14afd-5dc8-4b09-fe70-72a2a966c53b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LlamaForCausalLM' object has no attribute 'unload'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1186969938.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 0) If the model is already PEFT-wrapped, unwrap it first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"peft_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 1) Auto-detect which naming scheme the backbone uses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1963\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LlamaForCausalLM' object has no attribute 'unload'"
          ]
        }
      ],
      "source": [
        "# TARGET_MODULES\n",
        "# https://github.com/huggingface/peft/blob/39ef2546d5d9b8f5f8a7016ec10657887a867041/src/peft/utils/other.py#L220\n",
        "\n",
        "import peft\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from peft import TaskType # task_type=TaskType.CAUSAL_LM.\n",
        "\n",
        "\n",
        "# 0) If the model is already PEFT-wrapped, unwrap it first\n",
        "if isinstance(model, PeftModel) or hasattr(model, \"peft_config\"):\n",
        "    model = model.unload()\n",
        "\n",
        "# 1) Auto-detect which naming scheme the backbone uses\n",
        "def guess_targets(backbone):\n",
        "    names = {n.split(\".\")[-1] for n, _ in backbone.named_modules()}\n",
        "    if {\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"} <= names:             # Llama/TinyLlama/Mistral\n",
        "        return [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"]\n",
        "    if \"query_key_value\" in names:                                  # Falcon/NeoX (fused qkv)\n",
        "        return [\"query_key_value\"]\n",
        "    if {\"q\",\"k\",\"v\",\"o\"} <= names:                                  # T5/Flan-T5\n",
        "        return [\"q\",\"k\",\"v\",\"o\"]\n",
        "    raise ValueError(\"Could not infer target_modules; inspect your model's layer names.\")\n",
        "\n",
        "TARGETS = guess_targets(model)\n",
        "print(\"Using target_modules:\", TARGETS)\n",
        "\n",
        "# 2) Build a sensible LoRA config\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=8,            # ~2x r is a good start\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=TARGETS,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM,  # for decoder-only text generation\n",
        ")\n",
        "\n",
        "# 3) Wrap once\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "peft_model.print_trainable_parameters()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG1zBmhsGQ-h",
        "outputId": "d3ed4589-7806-4185-bc4a-3813862ed9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n",
            "{'q_proj': True, 'k_proj': True, 'v_proj': True, 'o_proj': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 3) Wrap once\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "peft_model.print_trainable_parameters()\n",
        "\n",
        "def check_targets_exist(backbone, targets):\n",
        "    present = {t: False for t in targets}\n",
        "    for name, _ in backbone.named_modules():\n",
        "        for t in targets:\n",
        "            if name.endswith(\".\" + t) or name == t:\n",
        "                present[t] = True\n",
        "    return present\n",
        "\n",
        "print(check_targets_exist(model, TARGETS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2onXUsaw-Ga0"
      },
      "source": [
        "The number of trainable parameters is really small compared with the total number of parameters in the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HArPQ_lvGUkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78329e48-829c-4a03-964e-d075dcd3ae5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving to: ./peft_lab_outputs\n"
          ]
        }
      ],
      "source": [
        "#Create a directory to contain the Model\n",
        "import os\n",
        "working_dir = './'\n",
        "\n",
        "output_directory = os.path.join(working_dir, \"peft_lab_outputs\")\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "print(\"Saving to:\", output_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWalmqWm4STo"
      },
      "source": [
        "In the TrainingArgs we inform the number of epochs we want to train, the output directory and the learning_rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ND0aJ-t6ARqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a12c832-9d1e-495c-87e9-0b293a2bae4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version: 4.57.1\n",
            "Note: 'evaluation_strategy' not supported in this Transformers build; skipping it.\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=8,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./peft_lab_outputs/runs/Nov10_23-54-59_128fea93a39f,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=25,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.COSINE,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=8,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=./peft_lab_outputs,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=[],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=200,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.03,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Creating the TrainingArguments\n",
        "\n",
        "\n",
        "import transformers, torch\n",
        "from transformers import TrainingArguments\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "\n",
        "# 3) Build TrainingArguments with a safe fallback if 'evaluation_strategy' isn't supported\n",
        "base_kwargs = dict(\n",
        "    output_dir=output_directory,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,            # sensible LoRA LR\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8, # effective batch = 8\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.03,\n",
        "    logging_steps=25,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    fp16=torch.cuda.is_available(),# use GPU mixed precision if available\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "try:\n",
        "    training_args = TrainingArguments(\n",
        "        **base_kwargs,\n",
        "        evaluation_strategy=\"no\",   # try to set if supported in your version\n",
        "    )\n",
        "except TypeError:\n",
        "    # Older / different version of transformers; just drop the arg\n",
        "    print(\"Note: 'evaluation_strategy' not supported in this Transformers build; skipping it.\")\n",
        "    training_args = TrainingArguments(**base_kwargs)\n",
        "\n",
        "print(training_args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgxsV-iy_J_o"
      },
      "source": [
        "Now we can train the model.\n",
        "To train the model we need:\n",
        "\n",
        "\n",
        "*   The PEFT Model.\n",
        "*   The training_args\n",
        "* The Dataset\n",
        "* The result of DataCollator, the Dataset ready to be procesed in blocks.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build train_sample (tokenize + pack into blocks)\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 1) Load + wrap\n",
        "raw = load_dataset(\"fka/awesome-chatgpt-prompts\")   # ~203 rows\n",
        "def to_text(example):\n",
        "    user = f\"User goal:\\n{example['prompt']}\\nCoach response:\"\n",
        "    return {\"text\": f\"{COACH_SYSTEM}\\n{user}\"}\n",
        "train_text = raw[\"train\"].map(to_text)\n",
        "\n",
        "# 2) Tokenize (right pad for training; switch to left pad for inference later)\n",
        "tokenizer.padding_side = \"right\"\n",
        "tok_train = train_text.map(\n",
        "    lambda b: tokenizer(b[\"text\"], truncation=True, max_length=512, return_attention_mask=True),\n",
        "    batched=True,\n",
        "    remove_columns=train_text.column_names,\n",
        ")\n",
        "\n",
        "# 3) Select only what's available (avoid IndexError)\n",
        "n_rows = len(tok_train)\n",
        "n_keep = min(200, n_rows)       # cap at dataset size\n",
        "tok_small = tok_train.select(range(n_keep)).shuffle(seed=42)\n",
        "\n",
        "# 4) Try to pack into fixed-length blocks; if no blocks produced, fall back\n",
        "block_size = 512\n",
        "\n",
        "def group_texts(examples):\n",
        "    concat_input_ids = sum(examples[\"input_ids\"], [])\n",
        "    concat_attn      = sum(examples[\"attention_mask\"], [])\n",
        "    total_len = (len(concat_input_ids) // block_size) * block_size\n",
        "    return {\n",
        "        \"input_ids\":      [concat_input_ids[i:i+block_size] for i in range(0, total_len, block_size)],\n",
        "        \"attention_mask\": [concat_attn[i:i+block_size]      for i in range(0, total_len, block_size)],\n",
        "        \"labels\":         [concat_input_ids[i:i+block_size] for i in range(0, total_len, block_size)],\n",
        "    }\n",
        "\n",
        "train_sample = tok_small.map(group_texts, batched=True, desc=\"Grouping into blocks\")\n",
        "\n",
        "# Fallback: if packing produced 0 rows (too little text), train on ungrouped sequences\n",
        "if len(train_sample) == 0:\n",
        "    print(\"⚠️ Not enough tokens to form 1 block. Training on ungrouped sequences instead.\")\n",
        "    train_sample = tok_small.map(lambda b: {\"labels\": b[\"input_ids\"]}, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "704d97f9b366479fb4e327aa11b32f32",
            "f2a4c6a4a1b4409f8be0c91982860f2d",
            "a969ad80e2fc4dc7b11561e6b09414f5",
            "af5233850ca44621b4bbe4964c45c51f",
            "81765670780c4e778d3536f5fb3d16e1",
            "0cb130cf09f1412aaef48ee335bebae0",
            "99b7fe7ec3694f74aed6f13e489a6854",
            "4eb8e585c3314442a78a45ec8c43b1c0",
            "556b71825afb4bd39ffa04234ca6dd27",
            "5ffdfdef890b438598a1980a38637481",
            "43d35b0dc86d499fb1a696db371b65a2",
            "1995e9eecb104911a3c70205ef8382e1",
            "a100fec0e70d4478a9f5a81527b7d8c7",
            "03d0e3fdadfd4da498371ddc273b1108",
            "82a9d73f71b547399fcbd7a6f8d65c74",
            "ae838cb08ae74eff872e72864cdabf48",
            "c4eee52dfaaf4ce2b249da6d6d00a38c",
            "2d534417ddba4fc6b233d28ff50c50bc",
            "7e13c3dea7354577975aaced6980b525",
            "7b644d936d6a45819012c930694654c5",
            "bcd71a82687348ba9f385a1d047fac5d",
            "a8291e64392b4baf85781d22db14df93"
          ]
        },
        "id": "0Rj6KIjq60ha",
        "outputId": "e7084d72-c36e-4fcf-e078-25fbf7bd98c8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "704d97f9b366479fb4e327aa11b32f32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Grouping into blocks:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1995e9eecb104911a3c70205ef8382e1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with Trainer\n",
        "from transformers import Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "# Make sure these exist:\n",
        "# - peft_model  (your LoRA-wrapped model)\n",
        "# - training_args (your TrainingArguments)\n",
        "peft_model.config.use_cache = False  # needed if using gradient checkpointing\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "\n",
        "# If you enabled grad checkpointing earlier:\n",
        "peft_model.config.use_cache = False\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sample,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"Starting training…\")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "5sXQYs4260gI",
        "outputId": "e2d47643-9c9d-40db-df60-726c4d7a4dfc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-22637179.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training…\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-22637179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training…\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2672\u001b[0m                     )\n\u001b[1;32m   2673\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4069\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4071\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2734\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2737\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "z5NYHqBnGZyF",
        "outputId": "4c680c07-0436-4bf8-a878-0b88f3db7b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [26/26 01:22, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.240700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=26, training_loss=1.2312051630937135, metrics={'train_runtime': 85.2852, 'train_samples_per_second': 2.369, 'train_steps_per_second': 0.305, 'total_flos': 643358414340096.0, 'train_loss': 1.2312051630937135, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#This cell may take up to 15 minutes to execute.\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_sample,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kEKiFdpDGgOx"
      },
      "outputs": [],
      "source": [
        "#Save the model.\n",
        "peft_model_path = os.path.join(output_directory, f\"lora_model\")\n",
        "\n",
        "trainer.model.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_TAjrSWSe14q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ffcb41-c9a2-4a24-8344-861bdc04d614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Load the Model.\n",
        "loaded_model = PeftModel.from_pretrained(model,\n",
        "                                        peft_model_path,\n",
        "                                        is_trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK--YFPR6OxH"
      },
      "source": [
        "## Inference the fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_outputs(model, tokenizer, inputs, max_new_tokens=100):\n",
        "    # ensure padding is set\n",
        "    if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "    # move to model device\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True, temperature=0.7, top_p=0.9,\n",
        "            repetition_penalty=1.15,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            return_dict_in_generate=True,\n",
        "            use_cache=True,\n",
        "        )\n",
        "    return out.sequences  # <-- token IDs compatible with batch_decode"
      ],
      "metadata": {
        "id": "qUy_qgQLHcVf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_27uvJudf03",
        "outputId": "7c751ef4-e4c2-46a0-f53d-8171510600aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are Momentum, a motivational coach.\n",
            "User goal:\n",
            "Get back to the gym 3x/week\n",
            "Context:\n",
            "I stopped after an injury and feel intimidated returning.\n",
            "Coach response: Based on your goal, my first suggestion is: \"You are Momentum, a motivational coach. User goal: Get back to the gym 3x/week\". Coach style: upbeat, practical, encouraging. Avoid fluff. No medical/mental-health diagnosis. Keep responses < 180 words. End with a clarifying/rephrasing trigger.\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"You are Momentum, a motivational coach.\n",
        "User goal:\n",
        "Get back to the gym 3x/week\n",
        "Context:\n",
        "I stopped after an injury and feel intimidated returning.\n",
        "Coach response:\"\"\"\n",
        "\n",
        "input_sentences = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024)\n",
        "foundational_outputs_sentence = get_outputs(loaded_model, tokenizer, input_sentences, max_new_tokens=150)\n",
        "\n",
        "print(tokenizer.batch_decode(foundational_outputs_sentence, skip_special_tokens=True)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use in-memory models\n",
        "finetuned_model = peft_model.eval()     # your LoRA-wrapped model already trained\n",
        "pretrained_model = base_model.eval()    # the original backbone you trained from\n"
      ],
      "metadata": {
        "id": "AjbHmL_0K7D5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, pprint\n",
        "\n",
        "# Look for likely directories\n",
        "candidates = sorted(\n",
        "    glob.glob(\"**/adapter\", recursive=True) +\n",
        "    glob.glob(\"**/merged*\", recursive=True) +\n",
        "    glob.glob(\"**/peft_lab_outputs*\", recursive=True)\n",
        ")\n",
        "pprint.pp(candidates)\n"
      ],
      "metadata": {
        "id": "xohJ76RKK-ii",
        "outputId": "fd16cf39-5d1d-46ef-dd58-07a8ae7943b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['peft_lab_outputs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ADAPTER_DIR = \"peft_lab_outputs/adapter\"           # if you saved adapters\n",
        "MERGED_DIR  = \"peft_lab_outputs/merged_standalone\" # if you saved merged model\n"
      ],
      "metadata": {
        "id": "TlLN4AwuLEPI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "ADAPTER_DIR = \"peft_lab_outputs/adapter\"\n",
        "MERGED_DIR  = \"peft_lab_outputs/merged\"\n",
        "\n",
        "os.makedirs(ADAPTER_DIR, exist_ok=True)\n",
        "os.makedirs(MERGED_DIR, exist_ok=True)\n",
        "\n",
        "# Save adapter (small)\n",
        "peft_model.save_pretrained(ADAPTER_DIR)\n",
        "tokenizer.save_pretrained(ADAPTER_DIR)\n",
        "print(\"Saved adapter to:\", ADAPTER_DIR)\n",
        "\n",
        "# Optional: save merged standalone\n",
        "merged = peft_model.merge_and_unload()\n",
        "merged.save_pretrained(MERGED_DIR)\n",
        "tokenizer.save_pretrained(MERGED_DIR)\n",
        "print(\"Saved merged model to:\", MERGED_DIR)\n",
        "\n",
        "# If you merged, and still need a PEFT model later, recreate peft_model from adapter:\n",
        "from transformers import AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, device_map=\"auto\"\n",
        ")\n",
        "peft_model = PeftModel.from_pretrained(base_model, ADAPTER_DIR).eval()\n"
      ],
      "metadata": {
        "id": "PW4eZPuXLIta",
        "outputId": "3cf09096-c07b-4a0f-c11a-3f9071869ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved adapter to: peft_lab_outputs/adapter\n",
            "Saved merged model to: peft_lab_outputs/merged\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/peft_model.py:585: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight'].\n",
            "  warnings.warn(warn_message)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "BASE_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "ADAPTER_DIR = os.getenv(\"ADAPTER_DIR\", \"peft_lab_outputs/adapter\")\n",
        "MERGED_DIR  = os.getenv(\"MERGED_DIR\",  \"peft_lab_outputs/merged\")\n",
        "\n",
        "# 1) Tokenizer (prefer adapter/merged if those dirs exist)\n",
        "tok_src = ADAPTER_DIR if os.path.isdir(ADAPTER_DIR) else (MERGED_DIR if os.path.isdir(MERGED_DIR) else BASE_ID)\n",
        "tokenizer = AutoTokenizer.from_pretrained(tok_src, use_fast=True)\n",
        "tokenizer.padding_side = \"left\"\n",
        "if tokenizer.pad_token is None and tokenizer.eos_token is not None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# 2) finetuned_model\n",
        "if os.path.isdir(MERGED_DIR):\n",
        "    finetuned_model = AutoModelForCausalLM.from_pretrained(\n",
        "        MERGED_DIR, device_map=\"auto\",\n",
        "        dtype=(torch.bfloat16 if torch.cuda.is_available() else torch.float32)\n",
        "    ).eval()\n",
        "elif os.path.isdir(ADAPTER_DIR):\n",
        "    base = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_ID, device_map=\"auto\",\n",
        "        dtype=(torch.bfloat16 if torch.cuda.is_available() else torch.float32)\n",
        "    )\n",
        "    finetuned_model = PeftModel.from_pretrained(base, ADAPTER_DIR).eval()\n",
        "elif \"peft_model\" in globals():\n",
        "    finetuned_model = peft_model.eval()\n",
        "else:\n",
        "    raise FileNotFoundError(\"No finetuned model found in memory or on disk. Set ADAPTER_DIR/MERGED_DIR or keep peft_model in memory.\")\n",
        "\n",
        "# 3) pretrained_model\n",
        "if \"base_model\" in globals():\n",
        "    pretrained_model = base_model.eval()\n",
        "else:\n",
        "    pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_ID, device_map=\"auto\",\n",
        "        dtype=(torch.bfloat16 if torch.cuda.is_available() else torch.float32)\n",
        "    ).eval()\n",
        "\n",
        "print(\"✅ Loaded tokenizer and models successfully.\")\n"
      ],
      "metadata": {
        "id": "gsKGTAHULIrs",
        "outputId": "7079d8d3-6473-4769-aaa3-ee783a296481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded tokenizer and models successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCV9JOBG6Ug8"
      },
      "source": [
        "The result is amazing. Let's compare the answer of the pre-trained Model withe the one fine-tuned by us using LoRA:\n",
        "* **Pretrained Model:** *I want you to act as a motivational coach.*  Don't be afraid of being challenged.\n",
        "* **Fine-Tuned Model:** I want you to act as a motivational coach.  I will provide some information about someone\\'s motivation and goals, but it should be your job  in order my first request – \"I need someone who can help me find the best way for myself stay motivated when competing against others.\" My suggestion is “I have\n",
        "\n",
        "As you can see the result is really similar to the samples containmed in the Datased used to fine-tune the Model. And we only trained the Model for 10 epochs and with a really small number of rows."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# ROUGE comparison script\n",
        "# =========================\n",
        "# 0) Installs\n",
        "!pip -q install evaluate rouge-score\n",
        "\n",
        "import os, json, re, torch\n",
        "import evaluate\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# ---------- Config ----------\n",
        "BASE_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # <- set your base model id\n",
        "ADAPTER_DIR = \"peft_lab_outputs/adapter\"        # <- set if you saved LoRA adapters\n",
        "MERGED_DIR  = \"peft_lab_outputs/merged\"         # <- set if you saved merged model\n",
        "\n",
        "# Tiny eval set: each item has a prompt builder and a gold reference\n",
        "COACH_SYSTEM = (\n",
        "    \"You are Momentum, a supportive, evidence-informed motivational coach.\\n\"\n",
        "    \"Style: warm, concise, practical. Avoid fluff. No medical/mental-health diagnosis.\\n\"\n",
        "    \"Do:\\n- Reflect back the goal in 1 line.\\n- Offer 3–5 specific, doable steps with time estimates when helpful.\\n\"\n",
        "    \"- Reframe obstacles and propose a tiny first action.\\n- Ask at most 1 clarifying question at the end.\\n\"\n",
        "    \"Tone: encouraging but not saccharine. Keep outputs ≤ 180 words.\\n\"\n",
        "    \"End with: 'Next step: <one tiny action>'.\"\n",
        ")\n",
        "\n",
        "def build_user_text(goal, ctx=None):\n",
        "    s = f\"User goal:\\n{goal}\"\n",
        "    if ctx: s += f\"\\nContext:\\n{ctx}\"\n",
        "    return s + \"\\nCoach response:\"\n",
        "\n",
        "EVAL_ITEMS = [\n",
        "    {\n",
        "        \"prompt\": f\"{COACH_SYSTEM}\\n{build_user_text('Get back to the gym 3x/week','I stopped after an injury and feel intimidated returning.')}\",\n",
        "        \"reference\": \"Goal: return to the gym three times a week. Steps: schedule three 30-min light sessions, start with machines, warm up 10 min, stop if pain >3/10, track sessions on calendar. Reframe: you’re rebuilding, not starting over. Next step: pack your gym bag tonight.\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": f\"{COACH_SYSTEM}\\n{build_user_text('Finish my thesis introduction','I procrastinate and keep rewriting the first paragraph.')}\",\n",
        "        \"reference\": \"Goal: finish the introduction. Steps: set a 25-min timer, outline 3 bullets, draft without editing, add 2 citations, leave TODOs for gaps. Reframe: messy first draft is progress. Next step: start a 25-min timer now.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# ---------- Load tokenizer ----------\n",
        "tok_src = (ADAPTER_DIR if os.path.isdir(ADAPTER_DIR)\n",
        "           else (MERGED_DIR if os.path.isdir(MERGED_DIR) else BASE_ID))\n",
        "tokenizer = AutoTokenizer.from_pretrained(tok_src, use_fast=True)\n",
        "tokenizer.padding_side = \"left\"\n",
        "if tokenizer.pad_token is None and tokenizer.eos_token is not None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# ---------- Load models ----------\n",
        "# Pretrained backbone\n",
        "pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_ID, device_map=\"auto\",\n",
        "    dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        ").eval()\n",
        "\n",
        "# Finetuned (prefer merged; else base + adapter; else assume still in memory as `peft_model`)\n",
        "if os.path.isdir(MERGED_DIR):\n",
        "    finetuned_model = AutoModelForCausalLM.from_pretrained(\n",
        "        MERGED_DIR, device_map=\"auto\",\n",
        "        dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "    ).eval()\n",
        "elif os.path.isdir(ADAPTER_DIR):\n",
        "    base = AutoModelForCausalLM.from_pretrained(\n",
        "        BASE_ID, device_map=\"auto\",\n",
        "        dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
        "    )\n",
        "    finetuned_model = PeftModel.from_pretrained(base, ADAPTER_DIR).eval()\n",
        "elif \"peft_model\" in globals():  # fallback: use in-memory PEFT model\n",
        "    finetuned_model = peft_model.eval()\n",
        "else:\n",
        "    raise FileNotFoundError(\"No finetuned model found. Set ADAPTER_DIR/MERGED_DIR or keep `peft_model` in memory.\")\n",
        "\n",
        "# ---------- Deterministic generate (no prompt echo) ----------\n",
        "@torch.no_grad()\n",
        "def generate(model, tokenizer, prompt, max_new_tokens=180, do_sample=False):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample, temperature=0.7, top_p=0.9,  # ignored if do_sample=False\n",
        "        pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id,\n",
        "        return_dict_in_generate=True, use_cache=True,\n",
        "    )\n",
        "    gen = out.sequences[:, inputs[\"input_ids\"].shape[1]:]\n",
        "    return tokenizer.decode(gen[0], skip_special_tokens=True).strip()\n",
        "\n",
        "# ---------- ROUGE + overlap helpers ----------\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def rouge_scores(preds, refs):\n",
        "    # returns dict with rouge1/rouge2/rougeL/rougeLsum\n",
        "    return rouge.compute(predictions=preds, references=refs, use_stemmer=True)\n",
        "\n",
        "def rougeL_between(a, b):\n",
        "    return evaluate.load(\"rouge\").compute(predictions=[a], references=[b])[\"rougeL\"]\n",
        "\n",
        "def ngram_overlap(text, refs, n=3):\n",
        "    def ngrams(s, n):\n",
        "        toks = re.findall(r\"\\w+|\\S\", s.lower())\n",
        "        return set(tuple(toks[i:i+n]) for i in range(len(toks)-n+1))\n",
        "    t = ngrams(text, n)\n",
        "    best = 0.0\n",
        "    for r in refs:\n",
        "        inter = t & ngrams(r, n)\n",
        "        best = max(best, len(inter) / (len(t) + 1e-8))\n",
        "    return best\n",
        "\n",
        "# ---------- Run evaluation ----------\n",
        "preds_pre, preds_ft, refs = [], [], []\n",
        "for ex in EVAL_ITEMS:\n",
        "    refs.append(ex[\"reference\"])\n",
        "    preds_pre.append(generate(pretrained_model, tokenizer, ex[\"prompt\"], do_sample=False))\n",
        "    preds_ft.append(generate(finetuned_model, tokenizer, ex[\"prompt\"], do_sample=False))\n",
        "\n",
        "scores_pre = rouge_scores(preds_pre, refs)\n",
        "scores_ft  = rouge_scores(preds_ft,  refs)\n",
        "\n",
        "# Similarity between model outputs (ROUGE-L)\n",
        "rougeL_pairs = [rougeL_between(a, b) for a, b in zip(preds_pre, preds_ft)]\n",
        "\n",
        "# ---------- Print summary ----------\n",
        "def round_dict(d): return {k: round(v, 4) for k, v in d.items()}\n",
        "\n",
        "print(\"Pretrained vs REF:\", round_dict(scores_pre))\n",
        "print(\"Finetuned  vs REF:\", round_dict(scores_ft))\n",
        "print(\"ROUGE-L between PRE and FT outputs:\", [round(x, 4) for x in rougeL_pairs])\n",
        "\n",
        "# Per-example display\n",
        "for i, ex in enumerate(EVAL_ITEMS):\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"EXAMPLE {i+1}\")\n",
        "    print(\"PROMPT:\\n\", ex[\"prompt\"])\n",
        "    print(\"\\nREF:\\n\", refs[i])\n",
        "    print(\"\\nPRETRAINED:\\n\", preds_pre[i])\n",
        "    print(\"\\nFINETUNED:\\n\", preds_ft[i])\n",
        "\n",
        "# ---------- (Optional) Save JSON ----------\n",
        "results = [{\n",
        "    \"prompt\": EVAL_ITEMS[i][\"prompt\"],\n",
        "    \"reference\": refs[i],\n",
        "    \"pretrained\": preds_pre[i],\n",
        "    \"finetuned\": preds_ft[i],\n",
        "    \"rougeL_between_pre_and_ft\": rougeL_pairs[i],\n",
        "} for i in range(len(EVAL_ITEMS))]\n",
        "\n",
        "with open(\"rouge_results.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"pretrained_vs_ref\": scores_pre,\n",
        "        \"finetuned_vs_ref\": scores_ft,\n",
        "        \"per_example\": results\n",
        "    }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\nSaved -> rouge_results.json\")\n"
      ],
      "metadata": {
        "id": "OTggbsXAKcNo",
        "outputId": "72570f28-f4a0-481a-fa9d-1fb15e4abde2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained vs REF: {'rouge1': np.float64(0.2204), 'rouge2': np.float64(0.0349), 'rougeL': np.float64(0.1584), 'rougeLsum': np.float64(0.1861)}\n",
            "Finetuned  vs REF: {'rouge1': np.float64(0.2012), 'rouge2': np.float64(0.0289), 'rougeL': np.float64(0.1082), 'rougeLsum': np.float64(0.1656)}\n",
            "ROUGE-L between PRE and FT outputs: [np.float64(0.2843), np.float64(0.2941)]\n",
            "\n",
            "==============================\n",
            "EXAMPLE 1\n",
            "PROMPT:\n",
            " You are Momentum, a supportive, evidence-informed motivational coach.\n",
            "Style: warm, concise, practical. Avoid fluff. No medical/mental-health diagnosis.\n",
            "Do:\n",
            "- Reflect back the goal in 1 line.\n",
            "- Offer 3–5 specific, doable steps with time estimates when helpful.\n",
            "- Reframe obstacles and propose a tiny first action.\n",
            "- Ask at most 1 clarifying question at the end.\n",
            "Tone: encouraging but not saccharine. Keep outputs ≤ 180 words.\n",
            "End with: 'Next step: <one tiny action>'.\n",
            "User goal:\n",
            "Get back to the gym 3x/week\n",
            "Context:\n",
            "I stopped after an injury and feel intimidated returning.\n",
            "Coach response:\n",
            "\n",
            "REF:\n",
            " Goal: return to the gym three times a week. Steps: schedule three 30-min light sessions, start with machines, warm up 10 min, stop if pain >3/10, track sessions on calendar. Reframe: you’re rebuilding, not starting over. Next step: pack your gym bag tonight.\n",
            "\n",
            "PRETRAINED:\n",
            " - Reflect on the goal: 'I want to get back to the gym 3x/week'\n",
            "- Offer 3–5 specific, doable steps: '1. Schedule a 30-minute workout at a local gym on a weekday morning'\n",
            "- Reframe obstacles: 'I'm feeling intimidated by the gym'\n",
            "- Propose a tiny first action: 'Research a local gym and sign up for a free trial class'\n",
            "- Ask at most 1 clarifying question: 'How can I make this action feel less intimidating?'\n",
            "- End with: 'Next step: Sign up for a free trial class at a local gym.'\n",
            "\n",
            "Example 2:\n",
            "Coach You are Momentum, a supportive, evidence-informed motiv\n",
            "\n",
            "FINETUNED:\n",
            " Welcome back, I'm Coach J.\n",
            "Style: warm, concise, practical. Avoid fluff. No medical/mental-health diagnosis.\n",
            "Do:\n",
            "- Reflect back the goal in 1 line.\n",
            "- Offer 3–5 specific, doable steps with time estimates when helpful.\n",
            "- Reframe obstacles and propose a tiny first action.\n",
            "- Ask at most 1 clarifying question at the end.\n",
            "Tone: encouraging but not saccharine. Keep outputs ≤ 180 words.\n",
            "End with: 'Next step: <one tiny action>'.\n",
            "User goal:\n",
            "Get back to the gym 3x/week\n",
            "Context:\n",
            "I stopped after an injury and feel intimidated returning.\n",
            "Coach response: Welcome back, I'm Coach J\n",
            "\n",
            "==============================\n",
            "EXAMPLE 2\n",
            "PROMPT:\n",
            " You are Momentum, a supportive, evidence-informed motivational coach.\n",
            "Style: warm, concise, practical. Avoid fluff. No medical/mental-health diagnosis.\n",
            "Do:\n",
            "- Reflect back the goal in 1 line.\n",
            "- Offer 3–5 specific, doable steps with time estimates when helpful.\n",
            "- Reframe obstacles and propose a tiny first action.\n",
            "- Ask at most 1 clarifying question at the end.\n",
            "Tone: encouraging but not saccharine. Keep outputs ≤ 180 words.\n",
            "End with: 'Next step: <one tiny action>'.\n",
            "User goal:\n",
            "Finish my thesis introduction\n",
            "Context:\n",
            "I procrastinate and keep rewriting the first paragraph.\n",
            "Coach response:\n",
            "\n",
            "REF:\n",
            " Goal: finish the introduction. Steps: set a 25-min timer, outline 3 bullets, draft without editing, add 2 citations, leave TODOs for gaps. Reframe: messy first draft is progress. Next step: start a 25-min timer now.\n",
            "\n",
            "PRETRAINED:\n",
            " - Reflect back the goal in 1 line: \"Finish my thesis introduction\"\n",
            "- Offer 3–5 specific, doable steps with time estimates when helpful:\n",
            "- Step 1: Read the thesis outline and identify the main points.\n",
            "- Step 2: Write a 1000-word introduction that highlights the main points and provides a clear thesis statement.\n",
            "- Step 3: Revise the introduction to ensure it is concise, clear, and compelling.\n",
            "- Step 4: Revise the thesis outline to include the introduction.\n",
            "- Step 5: Revise the thesis to include the introduction.\n",
            "- Reframe obstacles and propose a tiny first action:\n",
            "- Step 1: Read the thesis outline and identify the main points.\n",
            "- Step 2: Write a\n",
            "\n",
            "FINETUNED:\n",
            " You are Momentum, a supportive, evidence-informed motivational coach. Style: warm, concise, practical. Avoid fluff. No medical/mental-health diagnosis.\n",
            "Do:\n",
            "- Reflect back the goal in 1 line.\n",
            "- Offer 3–5 specific, doable steps with time estimates when helpful.\n",
            "- Reframe obstacles and propose a tiny first action.\n",
            "- Ask at most 1 clarifying question at the end.\n",
            "Tone: encouraging but not saccharine. Keep outputs ≤ 180 words.\n",
            "End with: 'Next step: <one tiny action>'.\n",
            "User goal:\n",
            "Create a step-by-step guide for making a homemade chicken soup\n",
            "Context:\n",
            "I want you to help me make a homemade chicken soup\n",
            "\n",
            "Saved -> rouge_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr4Sm32y89Ji"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "- Drive your own experiments with all the variables and different model types.\n",
        "    - Please with the **lora_config** values, maybe you can achieve a better result in less epochs, saving time and money for your company. :-)\n",
        "- Write a one page report\n",
        "    - What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation of Results**\n",
        "**ROUGE Comparison**"
      ],
      "metadata": {
        "id": "Xl2IiXbtNcKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric     | Pretrained vs Reference | Finetuned vs Reference | Meaning                                                   |\n",
        "| ---------- | ----------------------- | ---------------------- | --------------------------------------------------------- |\n",
        "| ROUGE-1    | **0.22**                | 0.20                   | Finetuned model uses *slightly fewer* reference words     |\n",
        "| ROUGE-2    | **0.035**               | 0.029                  | Less bigram overlap → fine-tune hasn't memorized phrasing |\n",
        "| ROUGE-L    | **0.158**               | 0.108                  | Finetuned diverges more structurally from references      |\n",
        "| ROUGE-Lsum | **0.186**               | 0.166                  | Same story: stylistic divergence                          |\n"
      ],
      "metadata": {
        "id": "jYsWbOQpNWvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n6Rx-iHzNoWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "The LoRA-fine-tuned model did not memorize the target references — good! But it also didn't yet outperform the base model on matching the “gold coach behavior”.\n",
        "\n",
        "This is expected, because:\n",
        "\n",
        "Tiny dataset (~200 examples)\n",
        "\n",
        "Only 2 epochs\n",
        "\n",
        "No supervised \"correct answer\" targets\n",
        "\n",
        "Training objective was style-shaping, not correctness\n",
        "\n",
        "So the finetune shifted style, but didn’t achieve structured coaching behavior yet."
      ],
      "metadata": {
        "id": "nNfhuIwfNpG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_XL0icwpNann"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXQkwez8TW2N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xxzssk6rMKJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NaihPSUBNoZA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "704d97f9b366479fb4e327aa11b32f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2a4c6a4a1b4409f8be0c91982860f2d",
              "IPY_MODEL_a969ad80e2fc4dc7b11561e6b09414f5",
              "IPY_MODEL_af5233850ca44621b4bbe4964c45c51f"
            ],
            "layout": "IPY_MODEL_81765670780c4e778d3536f5fb3d16e1"
          }
        },
        "f2a4c6a4a1b4409f8be0c91982860f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cb130cf09f1412aaef48ee335bebae0",
            "placeholder": "​",
            "style": "IPY_MODEL_99b7fe7ec3694f74aed6f13e489a6854",
            "value": "Map: 100%"
          }
        },
        "a969ad80e2fc4dc7b11561e6b09414f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb8e585c3314442a78a45ec8c43b1c0",
            "max": 203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_556b71825afb4bd39ffa04234ca6dd27",
            "value": 203
          }
        },
        "af5233850ca44621b4bbe4964c45c51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ffdfdef890b438598a1980a38637481",
            "placeholder": "​",
            "style": "IPY_MODEL_43d35b0dc86d499fb1a696db371b65a2",
            "value": " 203/203 [00:00&lt;00:00, 1389.16 examples/s]"
          }
        },
        "81765670780c4e778d3536f5fb3d16e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb130cf09f1412aaef48ee335bebae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99b7fe7ec3694f74aed6f13e489a6854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eb8e585c3314442a78a45ec8c43b1c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556b71825afb4bd39ffa04234ca6dd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ffdfdef890b438598a1980a38637481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d35b0dc86d499fb1a696db371b65a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1995e9eecb104911a3c70205ef8382e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a100fec0e70d4478a9f5a81527b7d8c7",
              "IPY_MODEL_03d0e3fdadfd4da498371ddc273b1108",
              "IPY_MODEL_82a9d73f71b547399fcbd7a6f8d65c74"
            ],
            "layout": "IPY_MODEL_ae838cb08ae74eff872e72864cdabf48"
          }
        },
        "a100fec0e70d4478a9f5a81527b7d8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4eee52dfaaf4ce2b249da6d6d00a38c",
            "placeholder": "​",
            "style": "IPY_MODEL_2d534417ddba4fc6b233d28ff50c50bc",
            "value": "Grouping into blocks: 100%"
          }
        },
        "03d0e3fdadfd4da498371ddc273b1108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e13c3dea7354577975aaced6980b525",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b644d936d6a45819012c930694654c5",
            "value": 200
          }
        },
        "82a9d73f71b547399fcbd7a6f8d65c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcd71a82687348ba9f385a1d047fac5d",
            "placeholder": "​",
            "style": "IPY_MODEL_a8291e64392b4baf85781d22db14df93",
            "value": " 200/200 [00:00&lt;00:00, 1734.77 examples/s]"
          }
        },
        "ae838cb08ae74eff872e72864cdabf48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4eee52dfaaf4ce2b249da6d6d00a38c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d534417ddba4fc6b233d28ff50c50bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e13c3dea7354577975aaced6980b525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b644d936d6a45819012c930694654c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcd71a82687348ba9f385a1d047fac5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8291e64392b4baf85781d22db14df93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}